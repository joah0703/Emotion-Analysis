{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1207wv_soft.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOZf2UgutkVhsShrFgdNyXA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Obm5XSj8ZWxo","executionInfo":{"status":"ok","timestamp":1639443541898,"user_tz":-540,"elapsed":25760,"user":{"displayName":"‍정유림[ 대학원석사과정재학 / 응용통계학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08082502813650172140"}},"outputId":"615f8fb3-09ca-4f99-90e9-ce80f5d14b4e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%tensorflow_version 1.x \n","\n","import urllib.request\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","\n","import tensorflow.keras\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import Lambda\n","from tensorflow.keras.layers import Dense, Input\n","from keras import optimizers\n","from tensorflow.keras.models import Model,Sequential\n","\n","import nltk\n","nltk.download('stopwords')\n","import nltk\n","nltk.download('wordnet')\n","import nltk\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","TensorFlow 1.x selected.\n"]},{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]},{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"UzjqRl3Hj7FX","executionInfo":{"status":"ok","timestamp":1639443561541,"user_tz":-540,"elapsed":362,"user":{"displayName":"‍정유림[ 대학원석사과정재학 / 응용통계학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08082502813650172140"}}},"source":["def split(data):\n","  #level이 1인 index list\n","  index1=[]\n","  for i in range(len(data)) :\n","    if data['level'][i]==1:\n","      index1.append(i)\n","\n","  #level이 2인 index list\n","  index2=[]\n","  for i in range(len(data)) :\n","    if data['level'][i]==2:\n","      index2.append(i)\n","  '''\n","  #level이 3인 index list\n","  index3=[]\n","  for i in range(len(data)) :\n","    if data['level'][i]==3:\n","      index3.append(i)\n","  '''\n","  print(\"level 1 개수 : \",len(index1))\n","  print(\"level 2 개수 : \",len(index2))  \n","  #print(\"level 3 개수 : \",len(index3))\n","  \n","  import random  #random.sample(list,k) -> list에서 k개 출력\n","\n","  datalen=len(data)\n","  trainlen=int(datalen*0.8)\n","  testlen=datalen-trainlen\n","\n","  index_test=random.sample(index1,int(testlen*0.3))\n","  index_test.extend(random.sample(index2,int(testlen*0.3)))\n","  #index_test.extend(random.sample(index3,int(testlen*0.3)))\n","  index_test.sort()\n","  print(\"test 개수 : \",len(index_test))\n","\n","  index_train=[]\n","  for i in range(0,datalen):        \n","      if i not in index_test:\n","          index_train.append(i)\n","  print(\"train 개수 : \",len(index_train))\n","\n","  #train index와 test index가 겹치지 않는 것을 확인\n","  for i in index_train:        \n","      if i in index_test:\n","          print(\"!!!\")\n","\n","  return index_train, index_test"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13iD0odysUn6"},"source":["**1. 데이터 불러오기**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"Ues8NhL7i4jc","executionInfo":{"status":"ok","timestamp":1607340956328,"user_tz":-540,"elapsed":1764,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"5c6f27a8-7eb8-4207-9a74-dde4dc213803"},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/인문감정/w2v_softmax')\n","%pwd\n","\n","raw_data= pd.read_csv('감정문장_1207_level.csv' , header=0)\n","dataset=raw_data.replace('n',0).replace('y',1)\n","dataset=dataset.replace('수심',1).replace('비탄',2).replace('우울',3)\n","dataset.head(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentence</th>\n","      <th>korean</th>\n","      <th>y1</th>\n","      <th>y2</th>\n","      <th>y3</th>\n","      <th>y4</th>\n","      <th>y5</th>\n","      <th>y6</th>\n","      <th>y7</th>\n","      <th>y8</th>\n","      <th>y9</th>\n","      <th>y10</th>\n","      <th>y11</th>\n","      <th>y12</th>\n","      <th>y13</th>\n","      <th>y14</th>\n","      <th>y15</th>\n","      <th>y16</th>\n","      <th>y17</th>\n","      <th>y18</th>\n","      <th>y19</th>\n","      <th>y20</th>\n","      <th>y21</th>\n","      <th>y22</th>\n","      <th>y23</th>\n","      <th>y24</th>\n","      <th>y25</th>\n","      <th>y26</th>\n","      <th>y27</th>\n","      <th>y28</th>\n","      <th>level</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>\"Lawrence Selden went from here to find you.\"\\...</td>\n","      <td>“로렌스 셀던이 여기 있다가 너를 찾으러 갔어.”\\n이 말에 돌처럼 단단하게 굳어 ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Depression?is?often?triggered?by?loss,?not?onl...</td>\n","      <td>우울증을 유발하는 계기는 상실일 때가 많다. 잃은 것은 사람일 수도 있지만, 우리가...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>The next day was a dreary one for Emma. Everyt...</td>\n","      <td>엠마에게 다음 날은 우울한 하루였다. 모든 것이 사물의 표면에 어지럽게 떠다니는 검...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                           sentence  ... y28  level\n","0           0  \"Lawrence Selden went from here to find you.\"\\...  ...   0      2\n","1           1  Depression?is?often?triggered?by?loss,?not?onl...  ...   0      2\n","2           2  The next day was a dreary one for Emma. Everyt...  ...   0      2\n","\n","[3 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"4h9skA3wwSnr","executionInfo":{"status":"ok","timestamp":1607340956330,"user_tz":-540,"elapsed":1760,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"6f2b5188-1d29-4cfb-8126-a8a97faed827"},"source":["del dataset['Unnamed: 0']\n","dataset.head(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>korean</th>\n","      <th>y1</th>\n","      <th>y2</th>\n","      <th>y3</th>\n","      <th>y4</th>\n","      <th>y5</th>\n","      <th>y6</th>\n","      <th>y7</th>\n","      <th>y8</th>\n","      <th>y9</th>\n","      <th>y10</th>\n","      <th>y11</th>\n","      <th>y12</th>\n","      <th>y13</th>\n","      <th>y14</th>\n","      <th>y15</th>\n","      <th>y16</th>\n","      <th>y17</th>\n","      <th>y18</th>\n","      <th>y19</th>\n","      <th>y20</th>\n","      <th>y21</th>\n","      <th>y22</th>\n","      <th>y23</th>\n","      <th>y24</th>\n","      <th>y25</th>\n","      <th>y26</th>\n","      <th>y27</th>\n","      <th>y28</th>\n","      <th>level</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"Lawrence Selden went from here to find you.\"\\...</td>\n","      <td>“로렌스 셀던이 여기 있다가 너를 찾으러 갔어.”\\n이 말에 돌처럼 단단하게 굳어 ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Depression?is?often?triggered?by?loss,?not?onl...</td>\n","      <td>우울증을 유발하는 계기는 상실일 때가 많다. 잃은 것은 사람일 수도 있지만, 우리가...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The next day was a dreary one for Emma. Everyt...</td>\n","      <td>엠마에게 다음 날은 우울한 하루였다. 모든 것이 사물의 표면에 어지럽게 떠다니는 검...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  ... level\n","0  \"Lawrence Selden went from here to find you.\"\\...  ...     2\n","1  Depression?is?often?triggered?by?loss,?not?onl...  ...     2\n","2  The next day was a dreary one for Emma. Everyt...  ...     2\n","\n","[3 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"markdown","metadata":{"id":"_BDytjoFshtk"},"source":["**2. 전처리 과정**\n","\n","> 1) train, test index 분리\n",">>*사용자 정의 함수( split() ) 사용*\n","\n","> 2) 문장 전처리"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-KKcgK2maUB","executionInfo":{"status":"ok","timestamp":1607340956331,"user_tz":-540,"elapsed":1756,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"1ebb48d2-4675-48c7-8cfe-2d81891c62e9"},"source":["index_train, index_test = split(dataset)\n","\n","X_train=dataset['sentence'][index_train]\n","X_test=dataset['sentence'][index_test]\n","\n","X_train=np.array(X_train)\n","X_test=np.array(X_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["level 1 개수 :  21\n","level 2 개수 :  62\n","test 개수 :  10\n","train 개수 :  73\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmswnta4s-ji","executionInfo":{"status":"ok","timestamp":1607340956333,"user_tz":-540,"elapsed":1753,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"570f1052-9591-473c-c50d-e06b8d6573a5"},"source":["# 특수 문자 제거\n","dataset['sentence'] = dataset['sentence'].str.replace(\"[^a-zA-Z]\", \" \")\n","# 전체 단어에 대한 소문자 변환\n","dataset['sentence'] = dataset['sentence'].apply(lambda x: x.lower())\n","\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","review_lines=list()\n","lines=dataset['sentence'].values.tolist()\n","\n","for line in lines:\n","  tokens=word_tokenize(line) #영어 corpus 토큰화\n","  tokens=[w.lower() for w in tokens]\n","  table=str.maketrans('','',string.punctuation)\n","  stripped=[w.translate(table) for w in tokens]\n","  words=[word for word in stripped if word.isalpha()]\n","  stop_words=set(stopwords.words(\"english\"))\n","  words=[w for w in words if not w in stop_words]\n","  review_lines.append(words)\n","  \n","print(len(review_lines))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["83\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BpI5jmtEpBBU","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1607340956334,"user_tz":-540,"elapsed":1749,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"cd10d2de-9eb5-4fde-ad4a-47c0783daef2"},"source":["'''\n","#문자열을 인덱스의 리스트로 변환\n","X_train_tokens=tokenizer_obj.texts_to_sequences(X_train)\n","X_test_tokens=tokenizer_obj.texts_to_sequences(X_test)\n","\n","X_train_pad= pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n","X_test_pad=pad_sequences(X_test_tokens,maxlen=max_length,padding='post')\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n#문자열을 인덱스의 리스트로 변환\\nX_train_tokens=tokenizer_obj.texts_to_sequences(X_train)\\nX_test_tokens=tokenizer_obj.texts_to_sequences(X_test)\\n\\nX_train_pad= pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\\nX_test_pad=pad_sequences(X_test_tokens,maxlen=max_length,padding='post')\\n\""]},"metadata":{"tags":[]},"execution_count":171}]},{"cell_type":"markdown","metadata":{"id":"rddelzgLxzc1"},"source":["**3. word2vec 임베딩**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jB2pMfvUqS0M","executionInfo":{"status":"ok","timestamp":1607340956809,"user_tz":-540,"elapsed":2219,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"a6b00dae-a580-449a-c957-4a90bc85f74c"},"source":["import gensim\n","EMBEDDING_DIM = 100\n","\n","model=gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=5, workers=4, min_count=1)\n","words=list(model.wv.vocab)\n","print(len(words))\n","\n","filename='1207_embedding_word2vec.txt'\n","model.wv.save_word2vec_format(filename,binary=False)\n","\n","import os\n","\n","embeddings_index={}\n","f=open(os.path.join('','1207_embedding_word2vec.txt'),encoding=\"utf-8\")\n","for line in f:\n","  values=line.split()\n","  word=values[0]\n","  coefs=np.asarray(values[1:])\n","  embeddings_index[word]=coefs\n","f.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1745\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j57Dp7q5x-Wi"},"source":["**4. 패딩(Padding)**"]},{"cell_type":"code","metadata":{"id":"PaBt-WfIqja-"},"source":["from tensorflow.python.keras.preprocessing.text import Tokenizer\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer_obj=Tokenizer()\n","tokenizer_obj.fit_on_texts(review_lines)\n","sequences=tokenizer_obj.texts_to_sequences(review_lines)\n","\n","word_index=tokenizer_obj.word_index\n","\n","max_length=max(len(s.split()) for s in dataset['sentence'])\n","max_length\n","vocab_size=len(tokenizer_obj.word_index)+1\n","vocab_size\n","\n","review_pad=pad_sequences(sequences,maxlen=max_length)\n","\n","X_train_pad=review_pad[index_train]\n","X_test_pad=review_pad[index_test]\n","\n","num_words=len(word_index)+1\n","embedding_matrix=np.zeros((num_words,EMBEDDING_DIM))\n","\n","for word, i in word_index.items():\n","  if i >num_words:\n","    continue\n","  embedding_vector = embeddings_index.get(word)\n","  if embedding_vector is not None :\n","    embedding_matrix[i]=embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wyHeRyEhw0-z"},"source":["**5. softmax를 이용하여 예측**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFiijUfxiEIG","executionInfo":{"status":"ok","timestamp":1607340957271,"user_tz":-540,"elapsed":2673,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"62f5e5f6-1978-4fbe-d2ae-05120334cc45"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, Flatten\n","from keras.layers.embeddings import Embedding\n","from keras.initializers import Constant\n","from keras import optimizers\n","\n","model=Sequential()\n","embedding_layer=Embedding(num_words, EMBEDDING_DIM, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False)\n","model.add(embedding_layer)\n","model.add(Flatten())\n","model.add(Dense(2,activation='softmax'))\n","adam = optimizers.Adam(lr=0.01,decay=0.1, amsgrad=False)\n","model.compile(loss='categorical_crossentropy',optimizer=adam, metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_10 (Embedding)     (None, 366, 100)          174600    \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 36600)             0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 2)                 73202     \n","=================================================================\n","Total params: 247,802\n","Trainable params: 73,202\n","Non-trainable params: 174,600\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYcqhJiBha5-","executionInfo":{"status":"ok","timestamp":1607340963182,"user_tz":-540,"elapsed":8579,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"35bb247a-355b-4226-afa2-94997d3f75f2"},"source":["#y1~y28까지 반복해서 예측\n","total_pred=[]\n","acc=[]\n","for i in range(2,30):\n","      print(\"<<\",dataset.columns[i],\">>\")\n","      y_train=np.asarray(dataset.iloc[index_train,i])\n","      y_test=np.asarray(dataset.iloc[index_test,i])\n","      y_train2=keras.utils.to_categorical(y_train,num_classes=2)\n","      y_test2=keras.utils.to_categorical(y_test,num_classes=2)\n","\n","      print(\"** train **\")\n","      history=model.fit(X_train_pad, y_train2, epochs=5, batch_size=34)\n","      print(\"** test **\")\n","      e_history=model.evaluate(X_test_pad, y_test2, batch_size=34)\n","      print(\"** predict **\")\n","      xhat = X_test_pad\n","      pred = model.predict(xhat)\n","\n","      prediction=[]\n","      for i in range(len(X_test_pad)) :\n","        if pred[i,0]>pred[i,1]:\n","            max_position=0\n","        else:\n","          max_position=1\n","        prediction.append(max_position)  \n","      \n","      total_pred.append(prediction)\n","      acc.extend(history.history['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<< y1 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.7534\n","Epoch 2/5\n","73/73 [==============================] - 0s 330us/step - loss: 0.6220 - accuracy: 1.0000\n","Epoch 3/5\n","73/73 [==============================] - 0s 407us/step - loss: 0.5842 - accuracy: 1.0000\n","Epoch 4/5\n","73/73 [==============================] - 0s 341us/step - loss: 0.5559 - accuracy: 1.0000\n","Epoch 5/5\n","73/73 [==============================] - 0s 397us/step - loss: 0.5329 - accuracy: 1.0000\n","** test **\n","10/10 [==============================] - 0s 7ms/step\n","** predict **\n","<< y2 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 326us/step - loss: 0.6243 - accuracy: 0.6849\n","Epoch 2/5\n","73/73 [==============================] - 0s 336us/step - loss: 0.6192 - accuracy: 0.6849\n","Epoch 3/5\n","73/73 [==============================] - 0s 377us/step - loss: 0.6139 - accuracy: 0.6849\n","Epoch 4/5\n","73/73 [==============================] - 0s 355us/step - loss: 0.6083 - accuracy: 0.6849\n","Epoch 5/5\n","73/73 [==============================] - 0s 363us/step - loss: 0.6031 - accuracy: 0.6849\n","** test **\n","10/10 [==============================] - 0s 442us/step\n","** predict **\n","<< y3 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 424us/step - loss: 0.6414 - accuracy: 0.6712\n","Epoch 2/5\n","73/73 [==============================] - 0s 391us/step - loss: 0.6360 - accuracy: 0.6712\n","Epoch 3/5\n","73/73 [==============================] - 0s 382us/step - loss: 0.6295 - accuracy: 0.6712\n","Epoch 4/5\n","73/73 [==============================] - 0s 412us/step - loss: 0.6228 - accuracy: 0.6712\n","Epoch 5/5\n","73/73 [==============================] - 0s 373us/step - loss: 0.6167 - accuracy: 0.6712\n","** test **\n","10/10 [==============================] - 0s 288us/step\n","** predict **\n","<< y4 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 370us/step - loss: 0.5709 - accuracy: 0.7808\n","Epoch 2/5\n","73/73 [==============================] - 0s 357us/step - loss: 0.5662 - accuracy: 0.7808\n","Epoch 3/5\n","73/73 [==============================] - 0s 439us/step - loss: 0.5619 - accuracy: 0.7808\n","Epoch 4/5\n","73/73 [==============================] - 0s 399us/step - loss: 0.5568 - accuracy: 0.7808\n","Epoch 5/5\n","73/73 [==============================] - 0s 394us/step - loss: 0.5522 - accuracy: 0.7808\n","** test **\n","10/10 [==============================] - 0s 487us/step\n","** predict **\n","<< y5 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 381us/step - loss: 0.6219 - accuracy: 0.6438\n","Epoch 2/5\n","73/73 [==============================] - 0s 319us/step - loss: 0.6189 - accuracy: 0.6438\n","Epoch 3/5\n","73/73 [==============================] - 0s 339us/step - loss: 0.6157 - accuracy: 0.6438\n","Epoch 4/5\n","73/73 [==============================] - 0s 353us/step - loss: 0.6126 - accuracy: 0.6438\n","Epoch 5/5\n","73/73 [==============================] - 0s 377us/step - loss: 0.6093 - accuracy: 0.6438\n","** test **\n","10/10 [==============================] - 0s 567us/step\n","** predict **\n","<< y6 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 380us/step - loss: 0.9593 - accuracy: 0.1507\n","Epoch 2/5\n","73/73 [==============================] - 0s 378us/step - loss: 0.9568 - accuracy: 0.1507\n","Epoch 3/5\n","73/73 [==============================] - 0s 385us/step - loss: 0.9523 - accuracy: 0.1507\n","Epoch 4/5\n","73/73 [==============================] - 0s 396us/step - loss: 0.9451 - accuracy: 0.1507\n","Epoch 5/5\n","73/73 [==============================] - 0s 375us/step - loss: 0.9375 - accuracy: 0.1507\n","** test **\n","10/10 [==============================] - 0s 587us/step\n","** predict **\n","<< y7 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 373us/step - loss: 0.8864 - accuracy: 0.1370\n","Epoch 2/5\n","73/73 [==============================] - 0s 396us/step - loss: 0.8798 - accuracy: 0.1507\n","Epoch 3/5\n","73/73 [==============================] - 0s 373us/step - loss: 0.8730 - accuracy: 0.1507\n","Epoch 4/5\n","73/73 [==============================] - 0s 392us/step - loss: 0.8661 - accuracy: 0.1507\n","Epoch 5/5\n","73/73 [==============================] - 0s 378us/step - loss: 0.8595 - accuracy: 0.1507\n","** test **\n","10/10 [==============================] - 0s 538us/step\n","** predict **\n","<< y8 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 373us/step - loss: 0.8943 - accuracy: 0.0959\n","Epoch 2/5\n","73/73 [==============================] - 0s 362us/step - loss: 0.8875 - accuracy: 0.0959\n","Epoch 3/5\n","73/73 [==============================] - 0s 390us/step - loss: 0.8809 - accuracy: 0.0959\n","Epoch 4/5\n","73/73 [==============================] - 0s 405us/step - loss: 0.8745 - accuracy: 0.0959\n","Epoch 5/5\n","73/73 [==============================] - 0s 399us/step - loss: 0.8682 - accuracy: 0.0959\n","** test **\n","10/10 [==============================] - 0s 514us/step\n","** predict **\n","<< y9 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 437us/step - loss: 0.9269 - accuracy: 0.0685\n","Epoch 2/5\n","73/73 [==============================] - 0s 397us/step - loss: 0.9211 - accuracy: 0.0685\n","Epoch 3/5\n","73/73 [==============================] - 0s 407us/step - loss: 0.9151 - accuracy: 0.0685\n","Epoch 4/5\n","73/73 [==============================] - 0s 387us/step - loss: 0.9088 - accuracy: 0.0685\n","Epoch 5/5\n","73/73 [==============================] - 0s 385us/step - loss: 0.9025 - accuracy: 0.0685\n","** test **\n","10/10 [==============================] - 0s 523us/step\n","** predict **\n","<< y10 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 362us/step - loss: 0.8971 - accuracy: 0.0548\n","Epoch 2/5\n","73/73 [==============================] - 0s 370us/step - loss: 0.8909 - accuracy: 0.0548\n","Epoch 3/5\n","73/73 [==============================] - 0s 405us/step - loss: 0.8855 - accuracy: 0.0548\n","Epoch 4/5\n","73/73 [==============================] - 0s 379us/step - loss: 0.8797 - accuracy: 0.0548\n","Epoch 5/5\n","73/73 [==============================] - 0s 407us/step - loss: 0.8743 - accuracy: 0.0548\n","** test **\n","10/10 [==============================] - 0s 520us/step\n","** predict **\n","<< y11 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 435us/step - loss: 0.7753 - accuracy: 0.2466\n","Epoch 2/5\n","73/73 [==============================] - 0s 393us/step - loss: 0.7724 - accuracy: 0.2466\n","Epoch 3/5\n","73/73 [==============================] - 0s 410us/step - loss: 0.7696 - accuracy: 0.2466\n","Epoch 4/5\n","73/73 [==============================] - 0s 433us/step - loss: 0.7671 - accuracy: 0.2466\n","Epoch 5/5\n","73/73 [==============================] - 0s 336us/step - loss: 0.7643 - accuracy: 0.2466\n","** test **\n","10/10 [==============================] - 0s 436us/step\n","** predict **\n","<< y12 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 366us/step - loss: 0.8413 - accuracy: 0.0959\n","Epoch 2/5\n","73/73 [==============================] - 0s 354us/step - loss: 0.8381 - accuracy: 0.0959\n","Epoch 3/5\n","73/73 [==============================] - 0s 342us/step - loss: 0.8348 - accuracy: 0.0959\n","Epoch 4/5\n","73/73 [==============================] - 0s 385us/step - loss: 0.8314 - accuracy: 0.0959\n","Epoch 5/5\n","73/73 [==============================] - 0s 379us/step - loss: 0.8277 - accuracy: 0.0959\n","** test **\n","10/10 [==============================] - 0s 577us/step\n","** predict **\n","<< y13 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 358us/step - loss: 0.8156 - accuracy: 0.0548\n","Epoch 2/5\n","73/73 [==============================] - 0s 367us/step - loss: 0.8119 - accuracy: 0.0685\n","Epoch 3/5\n","73/73 [==============================] - 0s 401us/step - loss: 0.8080 - accuracy: 0.0822\n","Epoch 4/5\n","73/73 [==============================] - 0s 423us/step - loss: 0.8046 - accuracy: 0.0822\n","Epoch 5/5\n","73/73 [==============================] - 0s 477us/step - loss: 0.8009 - accuracy: 0.0822\n","** test **\n","10/10 [==============================] - 0s 259us/step\n","** predict **\n","<< y14 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 473us/step - loss: 0.8188 - accuracy: 0.0685\n","Epoch 2/5\n","73/73 [==============================] - 0s 409us/step - loss: 0.8152 - accuracy: 0.0685\n","Epoch 3/5\n","73/73 [==============================] - 0s 376us/step - loss: 0.8115 - accuracy: 0.0685\n","Epoch 4/5\n","73/73 [==============================] - 0s 392us/step - loss: 0.8080 - accuracy: 0.0685\n","Epoch 5/5\n","73/73 [==============================] - 0s 457us/step - loss: 0.8047 - accuracy: 0.0685\n","** test **\n","10/10 [==============================] - 0s 626us/step\n","** predict **\n","<< y15 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 387us/step - loss: 0.8139 - accuracy: 0.0822\n","Epoch 2/5\n","73/73 [==============================] - 0s 349us/step - loss: 0.8111 - accuracy: 0.0822\n","Epoch 3/5\n","73/73 [==============================] - 0s 361us/step - loss: 0.8081 - accuracy: 0.0822\n","Epoch 4/5\n","73/73 [==============================] - 0s 466us/step - loss: 0.8051 - accuracy: 0.0822\n","Epoch 5/5\n","73/73 [==============================] - 0s 406us/step - loss: 0.8023 - accuracy: 0.0959\n","** test **\n","10/10 [==============================] - 0s 485us/step\n","** predict **\n","<< y16 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 379us/step - loss: 0.7772 - accuracy: 0.0959\n","Epoch 2/5\n","73/73 [==============================] - 0s 375us/step - loss: 0.7746 - accuracy: 0.1233\n","Epoch 3/5\n","73/73 [==============================] - 0s 352us/step - loss: 0.7719 - accuracy: 0.1370\n","Epoch 4/5\n","73/73 [==============================] - 0s 323us/step - loss: 0.7692 - accuracy: 0.1507\n","Epoch 5/5\n","73/73 [==============================] - 0s 436us/step - loss: 0.7665 - accuracy: 0.1507\n","** test **\n","10/10 [==============================] - 0s 388us/step\n","** predict **\n","<< y17 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 380us/step - loss: 0.7253 - accuracy: 0.2603\n","Epoch 2/5\n","73/73 [==============================] - 0s 382us/step - loss: 0.7237 - accuracy: 0.2740\n","Epoch 3/5\n","73/73 [==============================] - 0s 344us/step - loss: 0.7221 - accuracy: 0.2877\n","Epoch 4/5\n","73/73 [==============================] - 0s 364us/step - loss: 0.7205 - accuracy: 0.3014\n","Epoch 5/5\n","73/73 [==============================] - 0s 408us/step - loss: 0.7189 - accuracy: 0.3014\n","** test **\n","10/10 [==============================] - 0s 168us/step\n","** predict **\n","<< y18 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 371us/step - loss: 0.7481 - accuracy: 0.2192\n","Epoch 2/5\n","73/73 [==============================] - 0s 370us/step - loss: 0.7462 - accuracy: 0.2192\n","Epoch 3/5\n","73/73 [==============================] - 0s 391us/step - loss: 0.7443 - accuracy: 0.2192\n","Epoch 4/5\n","73/73 [==============================] - 0s 379us/step - loss: 0.7422 - accuracy: 0.2329\n","Epoch 5/5\n","73/73 [==============================] - 0s 411us/step - loss: 0.7401 - accuracy: 0.2603\n","** test **\n","10/10 [==============================] - 0s 669us/step\n","** predict **\n","<< y19 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 386us/step - loss: 0.7780 - accuracy: 0.2192\n","Epoch 2/5\n","73/73 [==============================] - 0s 417us/step - loss: 0.7760 - accuracy: 0.2466\n","Epoch 3/5\n","73/73 [==============================] - 0s 380us/step - loss: 0.7740 - accuracy: 0.2466\n","Epoch 4/5\n","73/73 [==============================] - 0s 395us/step - loss: 0.7719 - accuracy: 0.2466\n","Epoch 5/5\n","73/73 [==============================] - 0s 371us/step - loss: 0.7697 - accuracy: 0.2466\n","** test **\n","10/10 [==============================] - 0s 587us/step\n","** predict **\n","<< y20 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 371us/step - loss: 0.7454 - accuracy: 0.2603\n","Epoch 2/5\n","73/73 [==============================] - 0s 354us/step - loss: 0.7436 - accuracy: 0.2740\n","Epoch 3/5\n","73/73 [==============================] - 0s 390us/step - loss: 0.7416 - accuracy: 0.2740\n","Epoch 4/5\n","73/73 [==============================] - 0s 567us/step - loss: 0.7396 - accuracy: 0.2740\n","Epoch 5/5\n","73/73 [==============================] - 0s 354us/step - loss: 0.7376 - accuracy: 0.2877\n","** test **\n","10/10 [==============================] - 0s 432us/step\n","** predict **\n","<< y21 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 443us/step - loss: 0.7572 - accuracy: 0.2603\n","Epoch 2/5\n","73/73 [==============================] - 0s 426us/step - loss: 0.7553 - accuracy: 0.2603\n","Epoch 3/5\n","73/73 [==============================] - 0s 421us/step - loss: 0.7532 - accuracy: 0.2603\n","Epoch 4/5\n","73/73 [==============================] - 0s 414us/step - loss: 0.7513 - accuracy: 0.2603\n","Epoch 5/5\n","73/73 [==============================] - 0s 392us/step - loss: 0.7492 - accuracy: 0.2740\n","** test **\n","10/10 [==============================] - 0s 244us/step\n","** predict **\n","<< y22 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 419us/step - loss: 0.7032 - accuracy: 0.4795\n","Epoch 2/5\n","73/73 [==============================] - 0s 356us/step - loss: 0.7022 - accuracy: 0.4795\n","Epoch 3/5\n","73/73 [==============================] - 0s 413us/step - loss: 0.7010 - accuracy: 0.4932\n","Epoch 4/5\n","73/73 [==============================] - 0s 427us/step - loss: 0.6999 - accuracy: 0.5068\n","Epoch 5/5\n","73/73 [==============================] - 0s 425us/step - loss: 0.6988 - accuracy: 0.5068\n","** test **\n","10/10 [==============================] - 0s 475us/step\n","** predict **\n","<< y23 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 399us/step - loss: 0.6821 - accuracy: 0.4795\n","Epoch 2/5\n","73/73 [==============================] - 0s 383us/step - loss: 0.6811 - accuracy: 0.4795\n","Epoch 3/5\n","73/73 [==============================] - 0s 404us/step - loss: 0.6801 - accuracy: 0.5068\n","Epoch 4/5\n","73/73 [==============================] - 0s 396us/step - loss: 0.6790 - accuracy: 0.5068\n","Epoch 5/5\n","73/73 [==============================] - 0s 453us/step - loss: 0.6778 - accuracy: 0.5068\n","** test **\n","10/10 [==============================] - 0s 355us/step\n","** predict **\n","<< y24 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 400us/step - loss: 0.7356 - accuracy: 0.3151\n","Epoch 2/5\n","73/73 [==============================] - 0s 494us/step - loss: 0.7348 - accuracy: 0.3151\n","Epoch 3/5\n","73/73 [==============================] - 0s 425us/step - loss: 0.7338 - accuracy: 0.3151\n","Epoch 4/5\n","73/73 [==============================] - 0s 407us/step - loss: 0.7326 - accuracy: 0.3288\n","Epoch 5/5\n","73/73 [==============================] - 0s 418us/step - loss: 0.7313 - accuracy: 0.3288\n","** test **\n","10/10 [==============================] - 0s 609us/step\n","** predict **\n","<< y25 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 415us/step - loss: 0.6930 - accuracy: 0.5616\n","Epoch 2/5\n","73/73 [==============================] - 0s 444us/step - loss: 0.6922 - accuracy: 0.5753\n","Epoch 3/5\n","73/73 [==============================] - 0s 415us/step - loss: 0.6915 - accuracy: 0.6027\n","Epoch 4/5\n","73/73 [==============================] - 0s 415us/step - loss: 0.6905 - accuracy: 0.6027\n","Epoch 5/5\n","73/73 [==============================] - 0s 425us/step - loss: 0.6896 - accuracy: 0.6027\n","** test **\n","10/10 [==============================] - 0s 315us/step\n","** predict **\n","<< y26 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 501us/step - loss: 0.7244 - accuracy: 0.4384\n","Epoch 2/5\n","73/73 [==============================] - 0s 419us/step - loss: 0.7233 - accuracy: 0.4521\n","Epoch 3/5\n","73/73 [==============================] - 0s 419us/step - loss: 0.7220 - accuracy: 0.4521\n","Epoch 4/5\n","73/73 [==============================] - 0s 411us/step - loss: 0.7206 - accuracy: 0.4521\n","Epoch 5/5\n","73/73 [==============================] - 0s 428us/step - loss: 0.7192 - accuracy: 0.4521\n","** test **\n","10/10 [==============================] - 0s 260us/step\n","** predict **\n","<< y27 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 400us/step - loss: 0.7230 - accuracy: 0.4384\n","Epoch 2/5\n","73/73 [==============================] - 0s 416us/step - loss: 0.7217 - accuracy: 0.4658\n","Epoch 3/5\n","73/73 [==============================] - 0s 392us/step - loss: 0.7202 - accuracy: 0.4795\n","Epoch 4/5\n","73/73 [==============================] - 0s 435us/step - loss: 0.7188 - accuracy: 0.4932\n","Epoch 5/5\n","73/73 [==============================] - 0s 389us/step - loss: 0.7175 - accuracy: 0.5342\n","** test **\n","10/10 [==============================] - 0s 908us/step\n","** predict **\n","<< y28 >>\n","** train **\n","Epoch 1/5\n","73/73 [==============================] - 0s 397us/step - loss: 0.6969 - accuracy: 0.5616\n","Epoch 2/5\n","73/73 [==============================] - 0s 483us/step - loss: 0.6957 - accuracy: 0.5616\n","Epoch 3/5\n","73/73 [==============================] - 0s 435us/step - loss: 0.6946 - accuracy: 0.5616\n","Epoch 4/5\n","73/73 [==============================] - 0s 420us/step - loss: 0.6934 - accuracy: 0.5616\n","Epoch 5/5\n","73/73 [==============================] - 0s 456us/step - loss: 0.6922 - accuracy: 0.5753\n","** test **\n","10/10 [==============================] - 0s 293us/step\n","** predict **\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"879klGaJ9oXO","executionInfo":{"status":"ok","timestamp":1607340963183,"user_tz":-540,"elapsed":8576,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"09702df5-bd54-4574-9af7-f460636dc2e0"},"source":["import numpy as np\n","np.mean(acc)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.344227"]},"metadata":{"tags":[]},"execution_count":176}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyhoBdpuJfqv","executionInfo":{"status":"ok","timestamp":1607340963183,"user_tz":-540,"elapsed":8572,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"91b9e729-f680-4dc2-8f99-55fb2b4c248e"},"source":["total_pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{"tags":[]},"execution_count":177}]},{"cell_type":"code","metadata":{"id":"n4J-9QR5Q1Y0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607340963184,"user_tz":-540,"elapsed":8569,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"f7400fe7-61d2-41d8-870e-65c841ef1b87"},"source":["true_y=[]\n","for i in range(2,30):\n","  true_y.append(dataset.iloc[index_test,i].tolist())\n","\n","true_y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," [1, 1, 0, 1, 1, 0, 0, 0, 1, 0],\n"," [1, 1, 0, 1, 1, 0, 0, 0, 1, 0],\n"," [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n"," [1, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n"," [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n"," [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n"," [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n"," [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n"," [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n"," [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n"," [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"]},"metadata":{"tags":[]},"execution_count":178}]},{"cell_type":"code","metadata":{"id":"Lm-1Da2EJJaR"},"source":["false_num=0\n","for pred_list, true_list in zip(total_pred,true_y):\n","  for i in range(0,len(index_test)):\n","    if pred_list[i] != true_list[i]:\n","      false_num+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOX8Y-TbLxlW","executionInfo":{"status":"ok","timestamp":1607340963185,"user_tz":-540,"elapsed":8563,"user":{"displayName":"­정유림[ 학부재학 / 경제통계학부 빅데이터전공 ]","photoUrl":"","userId":"08082502813650172140"}},"outputId":"c9c6227d-41ca-421e-fe5a-42178288201f"},"source":["acc = 1-(false_num/(len(index_test)*28))\n","print(\"예측 정확도 :\",acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["예측 정확도 : 0.40714285714285714\n"],"name":"stdout"}]}]}